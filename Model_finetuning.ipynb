{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM69RHFLbRisFThoKj0DVh0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xD-0GnIGYlWf"},"outputs":[],"source":["!pip install -U langchain-community bitsandbytes transformers accelerate\n","!pip install transformers datasets pypdf"]},{"cell_type":"code","source":["import re\n","import json\n","import torch\n","import glob\n","import pandas as pd\n","\n","from tqdm import tqdm\n","from typing import List, Dict\n","from datasets import Dataset, load_dataset, load_from_disk\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, pipeline, BitsAndBytesConfig\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter"],"metadata":{"id":"pcJFG-Y6Ynqo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PDF Load & SPlit Chunk"],"metadata":{"id":"WLtGAmPZYpCi"}},{"cell_type":"code","source":["pdf_folder = \"/content/drive/MyDrive/Dacon/Data/PDF_files/*.pdf\"\n","pdf_files = glob.glob(pdf_folder)"],"metadata":{"id":"4ns8rdi-YrWE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","# 청크 분할기\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size = 500,\n","    chunk_overlap = 50\n",")\n","\n","# 2. 모든 문서를 불러와 합치기\n","all_docs = []\n","for pdf_file in tqdm(pdf_files, desc = \"PDF Load...\"):\n","    loader = PyPDFLoader(pdf_file)\n","    docs = loader.load()  # 페이지 단위로 로드됨\n","    all_docs.extend(docs) # 리스트에 추가\n","\n","all_chunks = text_splitter.split_documents(all_docs)\n","\n","print(f\"총 문서 수: {len(all_chunks)}\")"],"metadata":{"id":"1PpGG_JHYtf6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# QA Set"],"metadata":{"id":"M9LJTHYIYxUV"}},{"cell_type":"code","source":["model_name = \"skt/A.X-4.0-Light\"\n","\n","# 모델과 토크나이저 로드 (fp16, GPU 자동 할당)\n","tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side = \"left\")\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    torch_dtype = torch.float16,\n","    device_map = \"auto\"\n",")\n","\n","# 모든 청크를 prompts로 변환\n","contexts = [doc.page_content for doc in all_chunks]\n","prompts = [\n","    f\"\"\"\n","아래 문단을 바탕으로 객관식 질문 1개와 주관식 질문 1개를 만들어줘.\n","객관식은 4지선다로 하고 정답 표시 포함.\n","\n","문단 :\n","{context}\n","\"\"\" for context in contexts\n","]\n","\n","# 배치 처리\n","batch_size = 32\n","qa_dataset = []\n","\n","for i in tqdm(range(0, len(prompts), batch_size), desc = \"QA Dataset...\"):\n","    batch_prompts = prompts[i:i+batch_size]\n","    inputs = tokenizer(batch_prompts, return_tensors = \"pt\", padding = True, truncation = False).to(\"cuda\")\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens = 128,\n","            do_sample = False,\n","            eos_token_id = tokenizer.eos_token_id\n","        )\n","\n","    decoded = tokenizer.batch_decode(outputs, skip_special_tokens = True)\n","    for context, qa_text in zip(contexts[i:i+batch_size], decoded):\n","        qa_dataset.append({\"context\": context, \"qa\": qa_text})\n","\n","print(f\"총 {len(qa_dataset)}개의 QA 생성 완료\")"],"metadata":{"id":"5IXvXuSuYu7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"/content/drive/MyDrive/Dacon/Data/train_10.json\", \"w\", encoding = \"utf-8\") as f:\n","    for item in qa_dataset:\n","        json.dump({\n","            \"instruction\" : \"다음 문단에 대한 질문에 답하시오.\",\n","            \"input\" : item[\"context\"],\n","            \"output\" : item[\"qa\"]\n","        }, f, ensure_ascii = False)\n","        f.write(\"\\n\")"],"metadata":{"id":"hJ2hGtHAY0BM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fine-tuning"],"metadata":{"id":"VExwmE4jY5q2"}},{"cell_type":"code","source":["model_name = \"skt/A.X-4.0-Light\""],"metadata":{"id":"J-CDgd9qY6my"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 로드\n","dataset = load_dataset(\"json\", data_files = \"/content/drive/MyDrive/Dacon/Data/train_10.json\")\n","\n","# 모델, 토크나이저 로드\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map = None,\n","    torch_dtype = torch.bfloat16\n",")\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# LoRA 설정\n","lora_config = LoraConfig(\n","    lora_alpha = 32,\n","    lora_dropout = 0.05,\n","    r = 32,\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\"]\n",")\n","\n","# 모델에 LoRA 적용\n","model = get_peft_model(model, lora_config)\n","\n","# GPU로 옮기기\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"id":"PvXyDlKjY8MB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = dataset[\"train\"]\n","tokenizer.pad_token = tokenizer.eos_token  # pad_token 설정 (필수)\n","\n","# 3. 프롬프트 포맷 정의\n","def format_prompt(ex):\n","    if ex[\"input\"]:\n","        return f\"### Instruction:\\n{ex['instruction']}\\n\\n### Input:\\n{ex['input']}\\n\\n### Response:\\n{ex['output']}\"\n","    else:\n","        return f\"### Instruction:\\n{ex['instruction']}\\n\\n### Response:\\n{ex['output']}\"\n","\n","# 4. 토크나이징 함수\n","def preprocess_function(ex):\n","    prompt = format_prompt(ex)\n","    tokenized = tokenizer(prompt, truncation=True, padding = \"max_length\", max_length = 256)\n","    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n","    return tokenized\n","\n","# 5. 전처리 적용\n","tokenized_dataset = dataset.map(\n","    preprocess_function,\n","    batched = False,\n","    remove_columns = dataset.column_names\n",")"],"metadata":{"id":"KmUvYR3_Y9yP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset.save_to_disk(\"/content/drive/MyDrive/Dacon/Data/tokenized_dataset_10\")"],"metadata":{"id":"Nt37kSwtZCvj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset = load_from_disk(\"/content/drive/MyDrive/Dacon/Data/tokenized_dataset_10\")"],"metadata":{"id":"hUPqqutzZDNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training argument 설정\n","training_args = TrainingArguments(\n","    output_dir = \"/content/drive/MyDrive/Dacon/finetuned_model_10\",\n","    per_device_train_batch_size = 4,\n","    gradient_accumulation_steps = 4,\n","    learning_rate = 2e-4,\n","    num_train_epochs = 3,\n","    warmup_ratio = 0.05,\n","    logging_steps = 50,\n","    save_strategy = \"epoch\",\n","    eval_strategy = \"no\",\n","    fp16 = True,\n","    push_to_hub = False,\n","    report_to = \"none\"\n",")\n","\n","# 학습\n","trainer = Trainer(\n","    model = model,\n","    args = training_args,\n","    train_dataset = tokenized_dataset,\n","    tokenizer = tokenizer\n",")"],"metadata":{"id":"bEoQOMkAZEes"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습\n","trainer.train()\n","\n","# 모델 저장\n","trainer.save_model()"],"metadata":{"id":"djVtS2inZF7h"},"execution_count":null,"outputs":[]}]}